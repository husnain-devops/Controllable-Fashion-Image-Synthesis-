{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controllable Fashion Image Synthesis - AMD GPU Version\n",
    "\n",
    "## Setup Instructions for AMD GPUs (ROCm)\n",
    "\n",
    "### 1. Install PyTorch with ROCm Support\n",
    "\n",
    "**IMPORTANT**: Install PyTorch BEFORE running this notebook!\n",
    "\n",
    "```bash\n",
    "# Check your ROCm version\n",
    "rocm-smi --showdriverversion\n",
    "\n",
    "# For ROCm 6.0-6.12+ (recommended - best compatibility)\n",
    "pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.2\n",
    "\n",
    "# For older ROCm 5.7\n",
    "pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.7\n",
    "```\n",
    "\n",
    "### 2. Install Dependencies\n",
    "\n",
    "```bash\n",
    "cd /home/husnain/DLP\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### 3. Prepare Your Dataset\n",
    "\n",
    "Place your FashionGen dataset at:\n",
    "- `/home/husnain/DLP/data/fashiongen_256_256_train.h5`\n",
    "\n",
    "Or update the `FASHIONGEN_PATH` variable in Cell 1.\n",
    "\n",
    "### 4. Key Changes for AMD GPUs\n",
    "\n",
    "- ‚úÖ ROCm-compatible device detection\n",
    "- ‚úÖ FP16 mixed precision training support\n",
    "- ‚úÖ No bitsandbytes dependency (not ROCm compatible)\n",
    "- ‚úÖ Memory efficient attention with XFormers (if available)\n",
    "- ‚úÖ All paths updated to local filesystem\n",
    "\n",
    "---\n",
    "\n",
    "## Workflow Overview\n",
    "\n",
    "1. **Data Preparation** - Extract and prepare training/evaluation data\n",
    "2. **Environment Check** - Verify PyTorch and GPU availability\n",
    "3. **GPU Memory Check** - Monitor GPU memory\n",
    "4. **Training** - Fine-tune Stable Diffusion with LoRA\n",
    "5. **Training Visualization** - Plot training loss curves\n",
    "6. **Evaluation Setup** - Verify evaluation libraries\n",
    "7. **Image Generation** - Generate baseline and LoRA-enhanced images\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-13T05:45:13.240207Z",
     "iopub.status.busy": "2025-12-13T05:45:13.239812Z",
     "iopub.status.idle": "2025-12-13T05:45:20.725168Z",
     "shell.execute_reply": "2025-12-13T05:45:20.724385Z",
     "shell.execute_reply.started": "2025-12-13T05:45:13.240185Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husnain/DLP/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Opening dataset...\n",
      "üöÄ Exporting 100000 Training samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100000/100000 [09:36<00:00, 173.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Exporting 10000 Evaluation samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [01:56<00:00, 86.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data Prep Complete.\n"
     ]
    }
   ],
   "source": [
    "# CELL 1: Data Preparation\n",
    "import os\n",
    "import h5py\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "# --- Configuration ---\n",
    "FASHIONGEN_PATH = '/home/husnain/DLP/fashiongen_256_256_train.h5'  # Update this path to your dataset\n",
    "WORKING_DIR = \"./working\"\n",
    "TRAIN_ROOT = os.path.join(WORKING_DIR, \"fashion_train\")\n",
    "TRAIN_IMAGES_DIR = os.path.join(TRAIN_ROOT, \"images\")\n",
    "EVAL_ROOT = os.path.join(WORKING_DIR, \"eval_data\")\n",
    "EVAL_GT_DIR = os.path.join(EVAL_ROOT, \"gt\")\n",
    "\n",
    "# Create directories\n",
    "if os.path.exists(TRAIN_ROOT): shutil.rmtree(TRAIN_ROOT)\n",
    "if os.path.exists(EVAL_ROOT): shutil.rmtree(EVAL_ROOT)\n",
    "os.makedirs(TRAIN_IMAGES_DIR, exist_ok=True)\n",
    "os.makedirs(EVAL_GT_DIR, exist_ok=True)\n",
    "\n",
    "# --- Load Data ---\n",
    "print(\"üìÇ Opening dataset...\")\n",
    "h5_file = h5py.File(FASHIONGEN_PATH, 'r')\n",
    "num_total = len(h5_file['input_image'])\n",
    "\n",
    "# Define Split\n",
    "TRAIN_SIZE = 100000 \n",
    "EVAL_SIZE = 10000\n",
    "train_indices = range(0, TRAIN_SIZE)\n",
    "eval_indices = range(TRAIN_SIZE, TRAIN_SIZE + EVAL_SIZE)\n",
    "\n",
    "# --- 1. Export Training Data ---\n",
    "train_metadata = []\n",
    "print(f\"üöÄ Exporting {TRAIN_SIZE} Training samples...\")\n",
    "for idx in tqdm(train_indices):\n",
    "    img = Image.fromarray(h5_file['input_image'][idx])\n",
    "    file_name = f\"{idx:06d}.jpg\"\n",
    "    img.save(os.path.join(TRAIN_IMAGES_DIR, file_name), quality=95)\n",
    "    \n",
    "    desc = h5_file['input_description'][idx]\n",
    "    if isinstance(desc, bytes): desc = desc.decode('utf-8', errors='ignore')\n",
    "    prompt = str(desc).split(',')[0]\n",
    "    \n",
    "    # Path relative to TRAIN_ROOT\n",
    "    train_metadata.append({\"file_name\": f\"images/{file_name}\", \"text\": prompt})\n",
    "\n",
    "with open(os.path.join(TRAIN_ROOT, \"metadata.csv\"), 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"file_name\", \"text\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(train_metadata)\n",
    "\n",
    "# --- 2. Export Evaluation Data ---\n",
    "eval_configs = []\n",
    "print(f\"üöÄ Exporting {EVAL_SIZE} Evaluation samples...\")\n",
    "for idx in tqdm(eval_indices):\n",
    "    img = Image.fromarray(h5_file['input_image'][idx])\n",
    "    img.save(os.path.join(EVAL_GT_DIR, f\"{idx:06d}.png\"))\n",
    "    \n",
    "    desc = h5_file['input_description'][idx]\n",
    "    if isinstance(desc, bytes): desc = desc.decode('utf-8', errors='ignore')\n",
    "    prompt = str(desc).split(',')[0]\n",
    "    \n",
    "    eval_configs.append({\"idx\": idx, \"prompt\": prompt})\n",
    "\n",
    "with open(os.path.join(EVAL_ROOT, \"eval_configs.json\"), 'w') as f:\n",
    "    json.dump(eval_configs, f)\n",
    "\n",
    "print(\"‚úÖ Data Prep Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-12-13T05:45:22.891742Z",
     "iopub.status.busy": "2025-12-13T05:45:22.891440Z",
     "iopub.status.idle": "2025-12-13T05:47:20.822061Z",
     "shell.execute_reply": "2025-12-13T05:47:20.821375Z",
     "shell.execute_reply.started": "2025-12-13T05:45:22.891719Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.5.1+rocm6.2\n",
      "CUDA Available: True\n",
      "Device: AMD Instinct MI250X/MI250\n",
      "Device Count: 8\n",
      "üìú Downloading Training Script...\n",
      "‚úÖ Setup Complete. NumPy Version: 1.26.4\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: Installation (ROCm/AMD GPU Compatible)\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Check PyTorch and device availability\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Device Count: {torch.cuda.device_count()}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU detected. Training will use CPU (very slow).\")\n",
    "\n",
    "# Note: bitsandbytes is NOT installed as it has poor ROCm support\n",
    "# Training will use FP32 or FP16 depending on GPU capability\n",
    "\n",
    "# Download Training Script\n",
    "print(\"üìú Downloading Training Script...\")\n",
    "os.system(\"wget -q https://raw.githubusercontent.com/huggingface/diffusers/v0.26.3/examples/text_to_image/train_text_to_image_lora.py -O train_text_to_image_lora.py\")\n",
    "\n",
    "import numpy\n",
    "print(f\"‚úÖ Setup Complete. NumPy Version: {numpy.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-12-13T05:48:17.933285Z",
     "iopub.status.busy": "2025-12-13T05:48:17.932988Z",
     "iopub.status.idle": "2025-12-13T05:48:18.942247Z",
     "shell.execute_reply": "2025-12-13T05:48:18.941477Z",
     "shell.execute_reply.started": "2025-12-13T05:48:17.933264Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéÆ GPU: AMD Instinct MI250X/MI250\n",
      "üíæ Total GPU Memory: 63.98 GB\n",
      "üìä Allocated: 0.00 GB | Reserved: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "# CELL 2.5: Check GPU Memory\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    # Get GPU memory info\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"üíæ Total GPU Memory: {total_memory:.2f} GB\")\n",
    "    \n",
    "    # Clear cache\n",
    "    torch.cuda.empty_cache()\n",
    "    allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
    "    reserved = torch.cuda.memory_reserved(0) / 1024**3\n",
    "    print(f\"üìä Allocated: {allocated:.2f} GB | Reserved: {reserved:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU available, will use CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T05:48:21.561687Z",
     "iopub.status.busy": "2025-12-13T05:48:21.561146Z",
     "iopub.status.idle": "2025-12-13T05:49:15.355146Z",
     "shell.execute_reply": "2025-12-13T05:49:15.354396Z",
     "shell.execute_reply.started": "2025-12-13T05:48:21.561659Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting training with mixed_precision=no\n",
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_processes` was set to a value of `8`\n",
      "\t\tMore than one GPU was found, enabling multi-GPU training.\n",
      "\t\tIf this was unintended please pass in `--num_processes=1`.\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "/home/husnain/DLP/.venv/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/husnain/DLP/.venv/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/husnain/DLP/.venv/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/husnain/DLP/.venv/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/husnain/DLP/.venv/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/husnain/DLP/.venv/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/husnain/DLP/.venv/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/husnain/DLP/.venv/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "12/13/2025 18:11:07 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl\n",
      "Num processes: 8\n",
      "Process index: 7\n",
      "Local process index: 7\n",
      "Device: cuda:7\n",
      "\n",
      "Mixed precision type: no\n",
      "\n",
      "/home/husnain/DLP/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/husnain/DLP/.venv/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "12/13/2025 18:11:07 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl\n",
      "Num processes: 8\n",
      "Process index: 1\n",
      "Local process index: 1\n",
      "Device: cuda:1\n",
      "\n",
      "Mixed precision type: no\n",
      "\n",
      "/home/husnain/DLP/.venv/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/husnain/DLP/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/husnain/DLP/.venv/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/husnain/DLP/.venv/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "12/13/2025 18:11:07 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl\n",
      "Num processes: 8\n",
      "Process index: 3\n",
      "Local process index: 3\n",
      "Device: cuda:3\n",
      "\n",
      "Mixed precision type: no\n",
      "\n",
      "/home/husnain/DLP/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "12/13/2025 18:11:07 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl\n",
      "Num processes: 8\n",
      "Process index: 5\n",
      "Local process index: 5\n",
      "Device: cuda:5\n",
      "\n",
      "Mixed precision type: no\n",
      "\n",
      "/home/husnain/DLP/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "12/13/2025 18:11:07 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl\n",
      "Num processes: 8\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda:0\n",
      "\n",
      "Mixed precision type: no\n",
      "\n",
      "/home/husnain/DLP/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/husnain/DLP/.venv/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/husnain/DLP/.venv/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "12/13/2025 18:11:07 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl\n",
      "Num processes: 8\n",
      "Process index: 4\n",
      "Local process index: 4\n",
      "Device: cuda:4\n",
      "\n",
      "Mixed precision type: no\n",
      "\n",
      "/home/husnain/DLP/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "12/13/2025 18:11:07 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl\n",
      "Num processes: 8\n",
      "Process index: 6\n",
      "Local process index: 6\n",
      "Device: cuda:6\n",
      "\n",
      "Mixed precision type: no\n",
      "\n",
      "/home/husnain/DLP/.venv/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/husnain/DLP/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/husnain/DLP/.venv/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "12/13/2025 18:11:07 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl\n",
      "Num processes: 8\n",
      "Process index: 2\n",
      "Local process index: 2\n",
      "Device: cuda:2\n",
      "\n",
      "Mixed precision type: no\n",
      "\n",
      "/home/husnain/DLP/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "{'timestep_spacing', 'prediction_type', 'dynamic_thresholding_ratio', 'variance_type', 'rescale_betas_zero_snr', 'thresholding', 'clip_sample_range', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
      "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "{'time_embedding_dim', 'attention_type', 'time_embedding_act_fn', 'class_embeddings_concat', 'only_cross_attention', 'addition_embed_type', 'addition_time_embed_dim', 'class_embed_type', 'use_linear_projection', 'dual_cross_attention', 'resnet_time_scale_shift', 'upcast_attention', 'resnet_out_scale_factor', 'num_attention_heads', 'reverse_transformer_layers_per_block', 'num_class_embeds', 'cross_attention_norm', 'dropout', 'addition_embed_type_num_heads', 'conv_out_kernel', 'transformer_layers_per_block', 'projection_class_embeddings_input_dim', 'encoder_hid_dim', 'resnet_skip_time_act', 'mid_block_type', 'mid_block_only_cross_attention', 'time_embedding_type', 'conv_in_kernel', 'time_cond_proj_dim', 'encoder_hid_dim_type', 'timestep_post_act'} was not found in config. Values will be initialized to default values.\n",
      "Resolving data files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100001/100001 [00:00<00:00, 246606.99it/s]\n",
      "Resolving data files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100001/100001 [00:00<00:00, 246234.92it/s]\n",
      "Resolving data files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100001/100001 [00:00<00:00, 303539.33it/s]\n",
      "Resolving data files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100001/100001 [00:00<00:00, 242807.18it/s]\n",
      "Resolving data files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100001/100001 [00:00<00:00, 372410.34it/s]\n",
      "Resolving data files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100001/100001 [00:00<00:00, 241857.64it/s]\n",
      "Resolving data files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100001/100001 [00:00<00:00, 400742.37it/s]\n",
      "Resolving data files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100001/100001 [00:00<00:00, 388031.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100001/100001 [00:00<00:00, 145031.10files/s]\n",
      "Generating train split: 100000 examples [00:06, 16317.90 examples/s]\n",
      "[rank1]:[W1213 18:11:47.557116190 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[rank4]:[W1213 18:11:47.626904663 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[rank7]:[W1213 18:11:47.718730583 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[rank5]:[W1213 18:11:47.854906476 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[rank2]:[W1213 18:11:47.932397253 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[rank3]:[W1213 18:11:47.098005527 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[rank6]:[W1213 18:11:47.196760034 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[rank0]:[W1213 18:11:48.012291655 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "12/13/2025 18:11:51 - INFO - __main__ - ***** Running training *****\n",
      "12/13/2025 18:11:51 - INFO - __main__ -   Num examples = 100000\n",
      "12/13/2025 18:11:51 - INFO - __main__ -   Num Epochs = 2\n",
      "12/13/2025 18:11:51 - INFO - __main__ -   Instantaneous batch size per device = 2\n",
      "12/13/2025 18:11:51 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "12/13/2025 18:11:51 - INFO - __main__ -   Gradient Accumulation steps = 2\n",
      "12/13/2025 18:11:51 - INFO - __main__ -   Total optimization steps = 5000\n",
      "Steps:  20%|‚ñä   | 1000/5000 [05:45<21:23,  3.12it/s, lr=9.7e-5, step_loss=0.183]12/13/2025 18:17:36 - INFO - accelerate.accelerator - Saving current state to ./working/fashion_lora_output/checkpoint-1000\n",
      "12/13/2025 18:17:50 - INFO - accelerate.checkpointing - Model weights saved in ./working/fashion_lora_output/checkpoint-1000/model.safetensors\n",
      "12/13/2025 18:17:50 - INFO - accelerate.checkpointing - Optimizer state saved in ./working/fashion_lora_output/checkpoint-1000/optimizer.bin\n",
      "12/13/2025 18:17:50 - INFO - accelerate.checkpointing - Scheduler state saved in ./working/fashion_lora_output/checkpoint-1000/scheduler.bin\n",
      "12/13/2025 18:17:50 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in ./working/fashion_lora_output/checkpoint-1000/sampler.bin\n",
      "12/13/2025 18:17:50 - INFO - accelerate.checkpointing - Random states saved in ./working/fashion_lora_output/checkpoint-1000/random_states_0.pkl\n",
      "Model weights saved in ./working/fashion_lora_output/checkpoint-1000/pytorch_lora_weights.safetensors\n",
      "12/13/2025 18:17:50 - INFO - __main__ - Saved state to ./working/fashion_lora_output/checkpoint-1000\n",
      "Steps:  40%|‚ñä | 2000/5000 [11:26<17:27,  2.86it/s, lr=7.5e-5, step_loss=0.00838]12/13/2025 18:23:17 - INFO - accelerate.accelerator - Saving current state to ./working/fashion_lora_output/checkpoint-2000\n",
      "12/13/2025 18:23:31 - INFO - accelerate.checkpointing - Model weights saved in ./working/fashion_lora_output/checkpoint-2000/model.safetensors\n",
      "12/13/2025 18:23:31 - INFO - accelerate.checkpointing - Optimizer state saved in ./working/fashion_lora_output/checkpoint-2000/optimizer.bin\n",
      "12/13/2025 18:23:31 - INFO - accelerate.checkpointing - Scheduler state saved in ./working/fashion_lora_output/checkpoint-2000/scheduler.bin\n",
      "12/13/2025 18:23:31 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in ./working/fashion_lora_output/checkpoint-2000/sampler.bin\n",
      "12/13/2025 18:23:31 - INFO - accelerate.checkpointing - Random states saved in ./working/fashion_lora_output/checkpoint-2000/random_states_0.pkl\n",
      "Model weights saved in ./working/fashion_lora_output/checkpoint-2000/pytorch_lora_weights.safetensors\n",
      "12/13/2025 18:23:31 - INFO - __main__ - Saved state to ./working/fashion_lora_output/checkpoint-2000\n",
      "Steps:  60%|‚ñå| 3000/5000 [17:03<10:41,  3.12it/s, lr=4.14e-5, step_loss=0.00745]12/13/2025 18:28:55 - INFO - accelerate.accelerator - Saving current state to ./working/fashion_lora_output/checkpoint-3000\n",
      "12/13/2025 18:29:09 - INFO - accelerate.checkpointing - Model weights saved in ./working/fashion_lora_output/checkpoint-3000/model.safetensors\n",
      "12/13/2025 18:29:09 - INFO - accelerate.checkpointing - Optimizer state saved in ./working/fashion_lora_output/checkpoint-3000/optimizer.bin\n",
      "12/13/2025 18:29:09 - INFO - accelerate.checkpointing - Scheduler state saved in ./working/fashion_lora_output/checkpoint-3000/scheduler.bin\n",
      "12/13/2025 18:29:09 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in ./working/fashion_lora_output/checkpoint-3000/sampler.bin\n",
      "12/13/2025 18:29:09 - INFO - accelerate.checkpointing - Random states saved in ./working/fashion_lora_output/checkpoint-3000/random_states_0.pkl\n",
      "Model weights saved in ./working/fashion_lora_output/checkpoint-3000/pytorch_lora_weights.safetensors\n",
      "12/13/2025 18:29:09 - INFO - __main__ - Saved state to ./working/fashion_lora_output/checkpoint-3000\n",
      "Steps:  80%|‚ñà‚ñå| 4000/5000 [22:44<05:20,  3.12it/s, lr=1.17e-5, step_loss=0.0332]12/13/2025 18:34:36 - INFO - accelerate.accelerator - Saving current state to ./working/fashion_lora_output/checkpoint-4000\n",
      "12/13/2025 18:34:49 - INFO - accelerate.checkpointing - Model weights saved in ./working/fashion_lora_output/checkpoint-4000/model.safetensors\n",
      "12/13/2025 18:34:49 - INFO - accelerate.checkpointing - Optimizer state saved in ./working/fashion_lora_output/checkpoint-4000/optimizer.bin\n",
      "12/13/2025 18:34:49 - INFO - accelerate.checkpointing - Scheduler state saved in ./working/fashion_lora_output/checkpoint-4000/scheduler.bin\n",
      "12/13/2025 18:34:49 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in ./working/fashion_lora_output/checkpoint-4000/sampler.bin\n",
      "12/13/2025 18:34:49 - INFO - accelerate.checkpointing - Random states saved in ./working/fashion_lora_output/checkpoint-4000/random_states_0.pkl\n",
      "Model weights saved in ./working/fashion_lora_output/checkpoint-4000/pytorch_lora_weights.safetensors\n",
      "12/13/2025 18:34:49 - INFO - __main__ - Saved state to ./working/fashion_lora_output/checkpoint-4000\n",
      "Steps: 100%|‚ñà| 5000/5000 [28:18<00:00,  3.15it/s, lr=1.22e-11, step_loss=0.0088512/13/2025 18:40:10 - INFO - accelerate.accelerator - Saving current state to ./working/fashion_lora_output/checkpoint-5000\n"
     ]
    }
   ],
   "source": [
    "# CELL 3: Run Training (ROCm/AMD GPU Compatible)\n",
    "import torch\n",
    "\n",
    "OUTPUT_DIR = \"./working/fashion_lora_output\"\n",
    "\n",
    "# Determine mixed precision setting based on GPU\n",
    "# Note: FP16 has gradient scaling issues with ROCm - using FP32 for stability\n",
    "# FP32 is slower but more stable on AMD GPUs\n",
    "mixed_precision = \"no\"  # FP32 for ROCm compatibility\n",
    "\n",
    "print(f\"üöÄ Starting training with mixed_precision={mixed_precision}\")\n",
    "\n",
    "!accelerate launch --mixed_precision={mixed_precision} train_text_to_image_lora.py \\\n",
    "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
    "  --train_data_dir=\"./working/fashion_train\" \\\n",
    "  --caption_column=\"text\" \\\n",
    "  --resolution=256 \\\n",
    "  --random_flip \\\n",
    "  --train_batch_size=2 \\\n",
    "  --gradient_accumulation_steps=2 \\\n",
    "  --max_train_steps=5000 \\\n",
    "  --learning_rate=1e-04 \\\n",
    "  --max_grad_norm=1 \\\n",
    "  --lr_scheduler=\"cosine\" \\\n",
    "  --lr_warmup_steps=500 \\\n",
    "  --output_dir={OUTPUT_DIR} \\\n",
    "  --checkpointing_steps=1000 \\\n",
    "  --seed=42 \\\n",
    "  --report_to=\"tensorboard\"\n",
    "\n",
    "print(\"‚úÖ Training Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T05:49:19.814678Z",
     "iopub.status.busy": "2025-12-13T05:49:19.813919Z",
     "iopub.status.idle": "2025-12-13T05:49:20.457951Z",
     "shell.execute_reply": "2025-12-13T05:49:20.457354Z",
     "shell.execute_reply.started": "2025-12-13T05:49:19.814648Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Extracting training loss...\n",
      "‚ö†Ô∏è 'train_loss' not found in logs. (Did you run for enough steps?)\n"
     ]
    }
   ],
   "source": [
    "# CELL 4: Plot Training Loss from TensorBoard Logs\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "import glob\n",
    "import os\n",
    "\n",
    "print(\"üìä Extracting training loss...\")\n",
    "log_dir = \"./working/fashion_lora_output\"\n",
    "\n",
    "# Find the events file (it's inside a subfolder usually)\n",
    "event_files = glob.glob(f\"{log_dir}/**/events.out.tfevents.*\", recursive=True)\n",
    "\n",
    "if event_files:\n",
    "    # Load the most recent event file\n",
    "    ea = EventAccumulator(event_files[0])\n",
    "    ea.Reload()\n",
    "    \n",
    "    # Check available tags\n",
    "    tags = ea.Tags()['scalars']\n",
    "    if 'train_loss' in tags:\n",
    "        losses = ea.Scalars('train_loss')\n",
    "        steps = [x.step for x in losses]\n",
    "        vals = [x.value for x in losses]\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(steps, vals, label=\"Train Loss\", color='blue', alpha=0.6)\n",
    "        \n",
    "        # Add a moving average for smoothing\n",
    "        if len(vals) > 20:\n",
    "            window = 20\n",
    "            avg_vals = [sum(vals[i:i+window])/window for i in range(len(vals)-window)]\n",
    "            plt.plot(steps[window:], avg_vals, color='red', linewidth=2, label='Moving Avg')\n",
    "\n",
    "        plt.xlabel(\"Step\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training Loss Curve\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.legend()\n",
    "        \n",
    "        # Save\n",
    "        plt.savefig(\"training_loss.png\", dpi=150)\n",
    "        print(\"‚úÖ Saved 'training_loss.png'\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è 'train_loss' not found in logs. (Did you run for enough steps?)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No TensorBoard logs found in output directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T05:49:27.241968Z",
     "iopub.status.busy": "2025-12-13T05:49:27.241194Z",
     "iopub.status.idle": "2025-12-13T05:49:36.537363Z",
     "shell.execute_reply": "2025-12-13T05:49:36.536651Z",
     "shell.execute_reply.started": "2025-12-13T05:49:27.241942Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LPIPS and SSIM available\n",
      "‚úÖ CleanFID available\n",
      "‚úÖ Evaluation tools check complete.\n"
     ]
    }
   ],
   "source": [
    "# CELL 5: Verify Evaluation Libraries\n",
    "import os\n",
    "\n",
    "# Note: Evaluation tools should already be installed from requirements.txt\n",
    "# This cell just verifies they're available\n",
    "\n",
    "try:\n",
    "    import lpips\n",
    "    from skimage.metrics import structural_similarity as ssim\n",
    "    print(\"‚úÖ LPIPS and SSIM available\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Missing evaluation library: {e}\")\n",
    "    print(\"Run: pip install lpips scikit-image\")\n",
    "\n",
    "try:\n",
    "    from cleanfid import fid\n",
    "    print(\"‚úÖ CleanFID available\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è CleanFID not found. Run: pip install clean-fid\")\n",
    "\n",
    "print(\"‚úÖ Evaluation tools check complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T05:49:41.685687Z",
     "iopub.status.busy": "2025-12-13T05:49:41.685064Z",
     "iopub.status.idle": "2025-12-13T05:50:16.424912Z",
     "shell.execute_reply": "2025-12-13T05:50:16.424159Z",
     "shell.execute_reply.started": "2025-12-13T05:49:41.685660Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husnain/DLP/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/husnain/DLP/.venv/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/husnain/DLP/.venv/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéÆ Using device: cuda with dtype: torch.float16\n",
      "‚öôÔ∏è Loading Pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husnain/DLP/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading pipeline components...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00,  7.39it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.controlnet.pipeline_controlnet.StableDiffusionControlNetPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è XFormers not available, using default attention\n",
      "üöÄ Generating Baseline Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 177634.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Generating LoRA Images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LoRA: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 175229.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Generation Complete.\n",
      "üßπ GPU memory cleared\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# CELL 6: Generate Images for Evaluation (ROCm/AMD GPU Compatible)\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# --- Config ---\n",
    "EVAL_ROOT = \"./working/eval_data\"\n",
    "GT_DIR = os.path.join(EVAL_ROOT, \"gt\")\n",
    "BASE_DIR = os.path.join(EVAL_ROOT, \"baseline\")\n",
    "LORA_DIR = os.path.join(EVAL_ROOT, \"lora\")\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "os.makedirs(LORA_DIR, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(EVAL_ROOT, \"eval_configs.json\"), 'r') as f:\n",
    "    eval_configs = json.load(f)\n",
    "\n",
    "def get_canny_edge(pil_img):\n",
    "    img = np.array(pil_img)\n",
    "    edges = cv2.Canny(img, 100, 200)\n",
    "    edges = np.stack([edges]*3, axis=-1)\n",
    "    return Image.fromarray(edges)\n",
    "\n",
    "# --- Device Setup for AMD GPU ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "print(f\"üéÆ Using device: {device} with dtype: {dtype}\")\n",
    "\n",
    "# --- Load Pipeline ---\n",
    "print(\"‚öôÔ∏è Loading Pipeline...\")\n",
    "controlnet = ControlNetModel.from_pretrained(\"lllyasviel/control_v11p_sd15_canny\", torch_dtype=dtype)\n",
    "pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\", controlnet=controlnet, torch_dtype=dtype, safety_checker=None\n",
    ").to(device)\n",
    "pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "# Enable memory efficient attention if using ROCm\n",
    "if torch.cuda.is_available():\n",
    "    try:\n",
    "        pipe.enable_xformers_memory_efficient_attention()\n",
    "        print(\"‚úÖ XFormers memory efficient attention enabled\")\n",
    "    except:\n",
    "        print(\"‚ö†Ô∏è XFormers not available, using default attention\")\n",
    "\n",
    "# --- 1. Generate Baseline (ControlNet Only) ---\n",
    "print(\"üöÄ Generating Baseline Images...\")\n",
    "for item in tqdm(eval_configs, desc=\"Baseline\"):\n",
    "    idx = item['idx']\n",
    "    if os.path.exists(os.path.join(BASE_DIR, f\"{idx:06d}.png\")): continue\n",
    "    \n",
    "    gt_img = Image.open(os.path.join(GT_DIR, f\"{idx:06d}.png\")).convert(\"RGB\")\n",
    "    edge_img = get_canny_edge(gt_img)\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        gen = pipe(item['prompt'], image=edge_img, num_inference_steps=20).images[0]\n",
    "    gen.save(os.path.join(BASE_DIR, f\"{idx:06d}.png\"))\n",
    "\n",
    "# --- 2. Generate LoRA (ControlNet + Your Style) ---\n",
    "print(\"üöÄ Generating LoRA Images...\")\n",
    "pipe.load_lora_weights(\"./working/fashion_lora_output\", weight_name=\"pytorch_lora_weights.safetensors\")\n",
    "\n",
    "for item in tqdm(eval_configs, desc=\"LoRA\"):\n",
    "    idx = item['idx']\n",
    "    if os.path.exists(os.path.join(LORA_DIR, f\"{idx:06d}.png\")): continue\n",
    "    \n",
    "    gt_img = Image.open(os.path.join(GT_DIR, f\"{idx:06d}.png\")).convert(\"RGB\")\n",
    "    edge_img = get_canny_edge(gt_img)\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        gen = pipe(item['prompt'], image=edge_img, num_inference_steps=20).images[0]\n",
    "    gen.save(os.path.join(LORA_DIR, f\"{idx:06d}.png\"))\n",
    "\n",
    "print(\"‚úÖ Generation Complete.\")\n",
    "\n",
    "# Clear GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"üßπ GPU memory cleared\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 3324119,
     "sourceId": 5787457,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
